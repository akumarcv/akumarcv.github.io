<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Amit Kumar</title>
    <meta name="author" content="Amit Kumar">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
  </head>

  <body>
    <table style="width:100%;max-width:1200px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
      <tbody>
        <tr style="padding:0px">
          <td style="padding:0px">
            <!-- Introduction Section -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tbody>
                <tr style="padding:0px">
                  <td style="padding:2.5%;width:63%;vertical-align:middle">
                    <p class="name" style="text-align: center;">
                      Amit Kumar
                    </p>
                    <p>I'm a research scientist at Meta (previously Facebook), working in the XR Reality AI team, where my focus lie in human centric computer vision and understanding.</p>
                    <p>At Meta I've worked on Periocular authentication, 3D generative AI from self portraits, landmark tracking with transformers and realistic AI avatars. More recently I have been working with modelling human behaviors using Large Language Models and Diffusion. </p>
                    <p style="text-align:center">
                      <a href="mailto:iitkgp.ece.amit@hotmail.com">Email</a> &nbsp;/&nbsp;
                      <a href="data/resume_personal.pdf">CV</a> &nbsp;/&nbsp;
                      <a href="https://scholar.google.com/citations?user=qdWi6AMAAAAJ&hl=en">Scholar</a> &nbsp;/&nbsp;
                      <a href="https://www.linkedin.com/in/akumarcv/">LinkedIn</a> &nbsp;/&nbsp;
                      <a href="https://x.com/AmitKumarCV">Twitter</a> &nbsp;/&nbsp;
                      <a href="https://github.com/akumarcv">Github</a>
                    </p>
                  </td>
                  <td style="padding:2.5%;width:25%;max-width:25%">
                    <a href="images/self.JPG"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/self.JPG" class="hoverZoomLink"></a>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Two-column layout -->
            <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
              <tr>
                <!-- Left column - 40% width -->
                <td style="padding:20px;width:40%;vertical-align:top">
                  <!-- Education Section -->
                  <h2>Education</h2>
                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;">
                    <tbody>
                      <tr>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <strong>University of Maryland, College Park, Maryland</strong>
                          <br>
                          September 2014 - December 2019
                          <br>
                          MS + PhD, Electrical and Computer Engineering. 
                          <br>
                          Advisor: Rama Chellappa
                        </td>
                      </tr>
                      <tr>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <strong>Indian Institute of Technology, Kharagpur, India</strong>
                          <br>
                          July 2009 - May 2014
                          <br>
                          B. Tech (Hons) and MTech, Electronics and Communication Engineering 
                          <br>
                          Minor: Computer Science and Engineering
                        </td>
                      </tr>
                    </tbody>
                  </table>

                  <!-- Professional Experience Section -->
                  <h2>Professional Experience</h2>
                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;">
                    <tbody>
                      <tr>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <strong>Meta (previously Facebook Inc)</strong>
                          <br>
                          Research Scientist
                          <br>
                          Feb 2020 - Present
                        </td>
                      </tr>
                      <tr>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <strong>Snap Research Inc</strong>, NY
                          <br>
                          Research Intern
                          <br>
                          June 2018 – August 2018
                        </td>
                      </tr>
                      <tr>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <strong>IBM T.J. Watson Research Centre</strong>, Yorktown Heights, NY
                          <br>
                          Research Intern
                          <br>
                          June 2017 – August 2017
                        </td>
                      </tr>
                    </tbody>
                  </table>

                  <!-- Other Professional Activities Section -->
                  <h2>Other Professional Activities</h2>
                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;">
                    <tbody>
                      <tr>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <strong>Reviewer</strong>
                          <br>
                          IEEE Signal Processing Society and Computer Society (August 2018 - Present)
                          <br>
                          <ul style="margin-top:8px;margin-bottom:8px">
                            <li>IEEE Transactions of Neural Networks and Learning Systems</li>
                            <li>IEEE Signal Processing Letters</li>
                            <li>IEEE Transactions on Information Forensics and Security</li>
                            <li>IEEE Transactions on Image Processing</li>
                            <li>Springer International Journal of Computer Vision</li>
                            <li>ICCV'19-23</li>
                            <li>CVPR'20-24</li>
                            <li>ECCV'20-24</li>
                            <li>AAAI-2022</li>
                            <li>NeurIPS 2021-2023</li>
                          </ul>
                        </td>
                      </tr>
                    </tbody>
                  </table>
                </td>

                <!-- Right column - 60% width -->
                <td style="padding:20px;width:60%;vertical-align:top">
                  <!-- Research Section -->
                  <h2>Research</h2>
                  <p>I'm interested in computer vision, deep learning, generative AI, and image processing. Most of my research is about human centric computer vision, ranging from 3D generation of avatars to modeling and personalizing behaviors of these avatars. Some publications are listed below.</p>
                  
                  <!-- Research Papers -->
                  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                    <tbody>
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/talkingnerf.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }

                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">TalkinNeRF: Animatable Neural Fields for Full-Body Talking Humans</span>
                          <br>
                          <a href="https://aggelinacha.github.io/">Aggelina Chatziagapi</a>,
                          <a href="https://bindita.github.io/">Bindita Chaudhury</a>,
                          <strong>Amit Kumar</strong>,
                          <a href="https://scholar.google.co.in/citations?hl=en&user=8KF99lYAAAAJ&view_op=list_works&sortby=pubdate">Rakesh Ranjan</a>,
                          <a href="https://www.cs.stonybrook.edu/people/faculty/dimitrissamaras">Dimitris Samaras</a>,
                          <a href="https://nsarafianos.github.io/">Nikolaos Sarafianos</a>
                          <br>
                          <em>ECCV</em>, 2024
                          <br>
                          /
                          <a href="https://arxiv.org/abs/2409.16666">arXiv</a>
                          <p></p>
                          <p>TalkinNeRF is a unified NeRF-based network that represents the holistic 4D human motion. Given a monocular video of a subject, we learn corresponding modules for the body, face, and hands, that are combined together to generate the final result.</p>
                        </td>
                      </tr>
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/avface.jpg' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">AVFace: Towards Detailed Audio-Visual 4D Face Reconstruction</span>
                          <br>
                          <a href="https://aggelinacha.github.io/">Aggelina Chatziagapi</a>,
                          <a href="https://www.cs.stonybrook.edu/people/faculty/dimitrissamaras">Dimitris Samaras</a>,
                          <br>
                          <em>CVPR</em>, 2023
                          <br>
                          /
                          <a href="https://arxiv.org/abs/2409.16666">arXiv</a>
                          <p></p>
                          <p>AVFace incorporates both modalities (audio and video) and accurately reconstructs the 4D facial and lip motion of any speaker, without requiring any 3D ground truth for training.</p>
                        </td>
                      </tr>
      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/Hime.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">HIME: Efficient Headshot Image Super-Resolution with Multiple Exemplars</span>
                          <br>
                          <a href="https://xiaoyux1ang.github.io/">Xiaoyu Xiang</a>,
                          <a href="http://www.jamorton.com/">Jon Morton</a>,
                          <a href="https://fitsumreda.github.io/">Fitsum Reda</a>,
                          <a href="https://www.linkedin.com/in/lucasdyoung/">Lucas D Young</a>,
                          <a href="https://fperazzi.github.io/">Federico Perazzi</a>,
                          <a href="https://scholar.google.co.in/citations?hl=en&user=8KF99lYAAAAJ&view_op=list_works&sortby=pubdate">Rakesh Ranjan</a>,
                          
                          <strong>Amit Kumar</strong>,
                          <a href="http://andreacolaco.info/">Andrea Colaco</a>,
                          <a href="https://scholar.google.com/citations?user=wzG_DLwAAAAJ&hl=en">Jon P Allenbach</a>
                          <br>
                          <em>WACV</em>, 2024
                          <br>
                          /
                          <a href="https://arxiv.org/abs/2409.16666">arXiv</a>
                          <p></p>
                          <p>It is challenging to make the best use of multiple exemplars: the quality and alignment of each exemplar cannot be guaranteed. Using low-quality and mismatched images as references will impair the output results. To overcome these issues, we propose the efficient Headshot Image Super-Resolution with Multiple Exemplars network (HIME) method. </p>
                        </td>
                      </tr>
      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/eyepad.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">EyePAD++: A Distillation-based approach for joint Eye Authentication and Presentation Attack Detection
                            using Periocular Images</span>
                          <br>
                          <a href="https://sites.google.com/site/prithvirajdhar274/">Prithviraj Dhar</a>,
                          <strong>Amit Kumar</strong>,
                          <a href="https://www.linkedin.com/in/kirsten-kaplan-079203139/">Kirsten Kaplan</a>,
                          <a href="https://www.linkedin.com/in/khushi-gupta/">Khushi Gupta</a>,
                          <a href="https://scholar.google.co.in/citations?hl=en&user=8KF99lYAAAAJ&view_op=list_works&sortby=pubdate">Rakesh Ranjan</a>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          <br>
                          <em>CVPR</em>, 2022
                          <br>
                          /
                          <a href="https://openaccess.thecvf.com/content/CVPR2022/papers/Dhar_EyePAD_A_Distillation-Based_Approach_for_Joint_Eye_Authentication_and_Presentation_CVPR_2022_paper.pdf">arxiv</a>
                          <p></p>
                          <p>We propose Eye Authentication
                            with PAD (EyePAD), a distillation-based method that trains
                            a single network for EA and PAD while reducing the effect
                            of forgetting. </p>
                        </td>
                      </tr>
                      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/evrnet.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">EVRNet: Efficient Video Restoration on Edge Devices</span>
                          <br>
                          <a href="https://sacmehta.github.io/">Sachin Mehta</a>,
                          <strong>Amit Kumar</strong>,
                          <a href="https://fitsumreda.github.io/">Fitsum Reda</a>,
                          <a href="https://www.linkedin.com/in/varun-nasery-5353341a/">Varun Nasery</a>,
                          <a href="https://scholar.google.com/citations?user=jKO4YPsAAAAJ&hl=en">Vikram Mulukutla</a>,
                          <a href="https://scholar.google.co.in/citations?hl=en&user=8KF99lYAAAAJ&view_op=list_works&sortby=pubdate">Rakesh Ranjan</a>,
                          <a href="https://v-chandra.github.io/">Vikas Chandra</a>,
                          
                          <br>
                          <em>ACM-MM</em>, 2021
                          <br>
                          /
                          <a href="https://arxiv.org/pdf/2012.02228">arxiv</a>
                          <p></p>
                          <p>To restore
                            videos on recipient edge devices in real-time, we introduce an efficient video restoration network, EVRNet. EVRNet efficiently allocates parameters inside the network using alignment, differential, and fusion modules. </p>
                        </td>
                      </tr>
      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/RAE.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">Semi-Supervised Landmark-Guided Restoration of Atmospheric Turbulent Images</span>
                          <br>
                          <a href="https://sunanditapatra.wixsite.com/camp">Sunandita Patra</a>,
                          <a href="https://www.linkedin.com/in/james-cary-mason/">James Mason</a>,
                          <strong>Amit Kumar</strong>,
                          <a href="https://homepages.laas.fr/malik/Home/Home.html">Malik Ghallab</a>,
                          <a href="https://www.fbk.eu/en/paolo-traverso/">Paolo Traverso</a>,
                          <a href="https://www.cs.umd.edu/~nau/">Dana Nau</a>,
                          
                          <br>
                          <em>ICAPS</em>, 2020
                          <br>
                          /
                          <a href="https://ojs.aaai.org/index.php/ICAPS/article/view/6743/6597">arxiv</a>
                          <p></p>
                          <p>RAE uses hierarchical operational models to perform tasks in dynamically changing environments. </p>
                        </td>
                      </tr>
                      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/at.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">Semi-Supervised Landmark-Guided Restoration of
                            Atmospheric Turbulent Images</span>
                          <br>
                          <a href="https://samuel930930.github.io/">Samuel Chun Pong Lau</a>,
                          <strong>Amit Kumar</strong>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          
                          <br>
                          <em>IEEE Journal of Selected Topics in Signal Processing (JSTSP), 2021</em>, 2020
                          <br>
                          /
                          <a href="https://ieeexplore.ieee.org/abstract/document/9320575">IEEE</a>
                          <p></p>
                          <p>A semisupervised method for jointly extracting facial landmarks and restoring the degraded images by exploiting the semantic information from the landmarks. </p>
                        </td>
                      </tr>
      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/s2ld.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">S2LD: Semi-Supervised Landmark Detection in Low Resolution Images
                            and Impact on Face Verification</span>
                          <br>
                          <strong>Amit Kumar</strong>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          <br>
                          <em>CVPR-W</em>, 2020
                          <br>
                          /
                          <a href="https://openaccess.thecvf.com/content_CVPRW_2020/papers/w45/Kumar_S2LD_Semi-Supervised_Landmark_Detection_in_Low-Resolution_Images_and_Impact_on_CVPRW_2020_paper.pdf">arxiv</a>
                          <p></p>
                          <p>Predicting landmarks
                            directly on low resolution images is more effective than the
                            current practice of aligning images after rescaling or super-resolution. </p>
                        </td>
                      </tr>
                      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/cvprw19.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">Attention Driven Vehicle Re-identification and Unsupervised Anomaly Detection
                            for Traffic Understanding</span>
                          <br>
                          <a href="https://pirazh.github.io/">Pirazh Khorramshahi</a>,
                          <a href="https://www.neeharperi.com/">Neehar Peri</a>,
                          <strong>Amit Kumar</strong>,
                          <a href="https://anshulbshah.github.io/">Anshul Shah</a>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          <br>
                          <em>CVPR Nvidia City Challenge<strong> (Oral)</strong></em>, 2019
                          <br>
                          /
                          <a href="https://openaccess.thecvf.com/content_CVPRW_2019/papers/AI%20City/Khorramshahi_Attention_Driven_Vehicle_Re-identification_and_Unsupervised_Anomaly_Detection_for_Traffic_CVPRW_2019_paper.pdf">arxiv</a>
                          <p></p>
                          <p>We leverage an attention-based model
                            which learns to focus on different parts of a vehicle by conditioning the feature maps on visible key-points. We use
                            triplet embedding to reduce the dimensionality of the features obtained from the ensemble of networks trained using different datasets.</p>
                        </td>
                      </tr>
      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/AAVER.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">A Dual-Path Model With Adaptive Attention For Vehicle Re-Identification</span>
                          <br>
                          <a href="https://pirazh.github.io/">Pirazh Khorramshahi</a>,
                          <strong>Amit Kumar</strong>,
                          <a href="https://www.neeharperi.com/">Neehar Peri</a>,
                          <a href="https://rssaketh.github.io/">Sai Saketh Rambhatla</a>,
                          <a href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          <br>
                          <em>ICCV <strong> (Oral)</strong></em>, 2020
                          <br>
                          /
                          <a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Khorramshahi_A_Dual-Path_Model_With_Adaptive_Attention_for_Vehicle_Re-Identification_ICCV_2019_paper.pdf">arxiv</a>
                          <p></p>
                          <p>In AAVER, the global appearance path captures macroscopic vehicle features while the
                            orientation conditioned part appearance path learns to capture localized discriminative features by focusing attention
                            on the most informative key-points.</p>
                        </td>
                      </tr>
      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/cvprw2018.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">A Semi-Automatic 2D solution for
                            Vehicle Speed Estimation from Monocular Videos</span>
                          <br>
                          <strong>Amit Kumar</strong>,
                          <a href="https://pirazh.github.io/">Pirazh Khorramshahi</a>,
                          <a href="https://www.linkedin.com/in/wei-an-lin-01024075/">Wei-An Lin</a>,
                          <a href="https://rssaketh.github.io/">Prithviraj Dhar</a>,
                          <a href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          <br>
                          <em>CVPR Nvidia AI City Challenge <strong> (Oral)</strong></em>, 2018
                          <br>
                          /
                          <a href="https://openaccess.thecvf.com/content_cvpr_2018_workshops/papers/w3/Kumar_A_Semi-Automatic_2D_CVPR_2018_paper.pdf">arxiv</a>
                          <p></p>
                          <p>We propose a simple two-stage algorithm to approximate the transformation.
                            Images are first rectified to restore affine properties, then the
                            scaling factor is compensated for each scene.</p>
                        </td>
                      </tr>
      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/PCDCNN.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">Disentangling 3D Pose in A Dendritic CNN
                            for Unconstrained 2D Face Alignment</span>
                          <br>
                          <strong>Amit Kumar</strong>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          <br>
                          <em>CVPR</em>, 2018
                          <br>
                          /
                          <a href="https://openaccess.thecvf.com/content_cvpr_2018/papers/Kumar_Disentangling_3D_Pose_CVPR_2018_paper.pdf">CVPR</a>
                          <p></p>
                          <p>Following a Bayesian formulation, we disentangle the 3D pose of a face image explicitly by conditioning the landmark estimation on pose, making it different from multi-tasking approaches.</p>
                        </td>
                      </tr>
      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/kepler_conf.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">KEPLER: Simultaneous estimation of keypoints and 3D pose of unconstrained faces in a unified framework by learning efficient H-CNN regressors</span>
                          <br>
                          <strong>Amit Kumar</strong>,
                          <a href="https://www.rmit.edu.au/profiles/a/azadeh-alavi">Azadeh Alavi</a>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          <br>
                          <em>Elsevier Image and Vision Computing</em>, 2018
                          <br>
                          /
                          <a href="https://www.sciencedirect.com/science/article/abs/pii/S0262885618301549">arxiv</a>
                          <p></p>
                          <p>We present a novel architecture called H-CNN (Heatmap-CNN) acting on an N-dimensional input image which captures informative structured global and local features and thus favors accurate keypoint detecion in in-the wild face images.</p>
                        </td>
                      </tr>
                      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/kepler_conf.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">KEPLER: Keypoint and Pose Estimation of Unconstrained Faces by Learning Efficient H-CNN Regressors</span>
                          <br>
                          <strong>Amit Kumar</strong>,
                          <a href="https://www.rmit.edu.au/profiles/a/azadeh-alavi">Azadeh Alavi</a>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          <br>
                          <em>FG</em>, 2017
                          <br>
                          /
                          <a href="https://arxiv.org/abs/1702.05085">arxiv</a>
                          <p></p>
                          <p>Although a simple feed forward neural network can learn the mapping between input and output spaces, it cannot learn the inherent structural dependencies. We present a novel architecture called H-CNN (Heatmap-CNN) which captures structured global and local features and thus favors accurate keypoint detecion.</p>
                        </td>
                      </tr>
      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/ijcv.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">Unconstrained Still/Video-Based Face Verification with Deep Convolutional Neural Networks</span>
                          <br>
                          <a href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>,
                          <a href="https://scholar.google.com/citations?user=e3ejNaoAAAAJ&hl=en">Rajeev Ranjan</a>,
                          <a href="https://swamiviv.github.io/">Swami Sankaranarayanan</a>,
                          <strong>Amit Kumar</strong>,
                          <a href="https://scholar.google.com/citations?user=YHMyWm8AAAAJ&hl=en">Ching-Hui Chen</a>,
                          
                          <a href="https://engineering.jhu.edu/vpatel36/team/vishalpatel/">Vishal M. Patel</a>,
                          <a href="https://scholar.google.com/citations?user=jxf3Qv0AAAAJ&hl=en">Carlos D. Castillo</a>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          <br>
                          <em>IJCV</em>, 2017
                          <br>
                          /
                          <a href="https://engineering.jhu.edu/vpatel36/wp-content/uploads/2018/08/IJCV_20170517_v4.pdf">arxiv</a>
                          <p></p>
                          <p><strong>First Deep Learning</strong> based face verification system.</p>
                        </td>
                      </tr>
                      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/btas16.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">A Cascaded Convolutional Neural Network for Age Estimation
                            of Unconstrained Faces</span>
                          <br>
                          <a href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>,
                          <strong>Amit Kumar</strong>,
                          <a href="https://scholar.google.com/citations?user=e3ejNaoAAAAJ&hl=en">Rajeev Ranjan</a>,
                          <a href="https://engineering.jhu.edu/vpatel36/team/vishalpatel/">Vishal M. Patel</a>,
                          <a href="https://www.rmit.edu.au/profiles/a/azadeh-alavi">Azadeh Alavi</a>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          <br>
                          <em>BTAS</em>, 2016
                          <br>
                          /
                          <a href="https://engineering.jhu.edu/vpatel36/wp-content/uploads/2018/08/btas_age_2016_cameraready.pdf">arxiv</a>
                          <p></p>
                          <p>A coarse-to-fine approach for estimating the
                            apparent age from unconstrained face images using deep
                            convolutional neural networks (DCNNs). Also one of the first models in the <strong>Deep learning era</strong></p>
                        </td>
                      </tr>
      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/ITA.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">Towards the Design of an End-to-End Automated
                            System for Image and Video-based Recognition</span>
                          <br>
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          <a href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>,
                          <a href="https://scholar.google.com/citations?user=e3ejNaoAAAAJ&hl=en">Rajeev Ranjan</a>,
                          <a href="https://swamiviv.github.io/">Swami Sankaranarayanan</a>,
                          <strong>Amit Kumar</strong>,
                          <a href="https://engineering.jhu.edu/vpatel36/team/vishalpatel/">Vishal M. Patel</a>,
                          <a href="https://scholar.google.com/citations?user=jxf3Qv0AAAAJ&hl=en">Carlos D. Castillo</a>,
                          
                          <br>
                          <em>IEEE Information Theory and Applications</em>, 2016
                          <br>
                          /
                          <a href="https://arxiv.org/pdf/1601.07883">arxiv</a>
                          <p></p>
                          <p>A brief history of developments
                            in computer vision and artificial neural networks over the last
                            forty years for the problem of image-based recognition. We then
                            present the design details of a deep learning system for endto-end unconstrained face verification/recognition.</p>
                        </td>
                      </tr>
                      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/iccvw2015.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">An End-to-End System for Unconstrained Face Verification with Deep
                            Convolutional Neural Networks</span>
                          <br>
                          <a href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>,
                          <a href="https://scholar.google.com/citations?user=e3ejNaoAAAAJ&hl=en">Rajeev Ranjan</a>,
                          <strong>Amit Kumar</strong>,
                          <a href="https://scholar.google.com/citations?user=YHMyWm8AAAAJ&hl=en">Ching-Hui Chen</a>,
                          <a href="https://engineering.jhu.edu/vpatel36/team/vishalpatel/">Vishal M. Patel</a>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          
                          <br>
                          <em>ICCV Workshops</em>, 2015
                          <br>
                          /
                          <a href="https://engineering.jhu.edu/vpatel36/wp-content/uploads/2018/08/janus_system_camera_ready.pdf">arxiv</a>
                          
                          <p></p>
                          <p>The end-to-end system consists of three modules for face detection, alignment
                            and verification and is evaluated using the newly released
                            IARPA Janus Benchmark A (IJB-A) dataset.</p>
                        </td>
                      </tr>
      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/iccvw_2_2015.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">Unconstrained age estimation with deep convolutional neural networks</span>
                          <br>
                          <a href="https://scholar.google.com/citations?user=e3ejNaoAAAAJ&hl=en">Rajeev Ranjan</a>,
                          <a href="https://www.linkedin.com/in/sabrina-zhou-9a8925134/">Sabrina Zhou</a>,
                          <a href="https://homepage.citi.sinica.edu.tw/pages/pullpull/index_en.html">Jun-Cheng Chen</a>,
                          <strong>Amit Kumar</strong>,
                          <a href="https://www.rmit.edu.au/profiles/a/azadeh-alavi">Azadeh Alavi</a>,
                          <a href="https://engineering.jhu.edu/vpatel36/team/vishalpatel/">Vishal M. Patel</a>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          
                          <br>
                          <em>ICCV Workshops</em>, 2015
                          <br>
                          /
                          <a href="https://engineering.jhu.edu/vpatel36/wp-content/uploads/2018/08/Age_iccv2015.pdf">arxiv</a>
                          <p></p>
                          <p>The proposed approach exploits two insights: (1) Features obtained
                            from DCNN trained for face-identification task can be used
                            for age estimation. (2) The three-layer neural network regression method trained on Gaussian loss performs better
                            than traditional regression methods for apparent age estimation.</p>
                        </td>
                      </tr>
      
                      <tr onmouseout="power_stop()" onmouseover="power_start()">
                        <td style="padding:16px;width:20%;vertical-align:middle">
                          <div class="one">
                            <img src='images/lddr.png' width="160">
                          </div>
                          <script type="text/javascript">
                            function power_start() {
                              document.getElementById('power_image').style.opacity = "1";
                            }
      
                            function power_stop() {
                              document.getElementById('power_image').style.opacity = "0";
                            }
                            power_stop()
                          </script>
                        </td>
                        <td style="padding:8px;width:80%;vertical-align:middle">
                          <span class="papertitle">Face Alignment by Local Deep Descriptor Regression</span>
                          <br>
                          <strong>Amit Kumar</strong>,
                          <a href="https://scholar.google.com/citations?user=e3ejNaoAAAAJ&hl=en">Rajeev Ranjan</a>,
                          <a href="https://engineering.jhu.edu/vpatel36/team/vishalpatel/">Vishal M. Patel</a>,
                          <a href="https://engineering.jhu.edu/faculty/rama-chellappa/">Rama Chellappa</a>,
                          
                          <br>
                          <em>Arxiv</em>, 2015
                          <br>
                          /
                          <a href="https://arxiv.org/pdf/1601.07950">arxiv</a>
                          
                          <p></p>
                          <p>Local Deep
                            Descriptor Regression (LDDR) is able to localize face landmarks of varying sizes, poses and occlusions with high accuracy. Deep Descriptors presented in this paper are able
                            to uniquely and efficiently describe every pixel in the image
                            and therefore can potentially replace traditional descriptors
                            such as SIFT and HOG.</p>
                        </td>
                      </tr>
                    </tbody>
                  </table>
                </td>
              </tr>
            </table>
          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>